{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Entity Extraction from descripiton related to a book using Granite-8B*\n",
    "LLMs have demonstrated remarkable accuracy in the task of entity extraction. This cookbook focuses on extracting key entities from descriptions related to books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ibm-granite-community/utils\n",
      "  Cloning https://github.com/ibm-granite-community/utils to /private/var/folders/yq/mg65c_l16hv64plnb99z5dx40000gq/T/pip-req-build-4kuap8v3\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/ibm-granite-community/utils /private/var/folders/yq/mg65c_l16hv64plnb99z5dx40000gq/T/pip-req-build-4kuap8v3\n",
      "  Resolved https://github.com/ibm-granite-community/utils to commit 5d67648927240b208a164d2466f0dc77200450e5\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: langchain_community in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (0.3.13)\n",
      "Requirement already satisfied: pydantic in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (2.10.4)\n",
      "Requirement already satisfied: python-dotenv in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from ibm-granite-community-utils==0.1.dev49) (1.0.1)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.13 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (0.3.13)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (0.3.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (3.11.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (2.0.36)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (0.2.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (2.7.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from pydantic) (4.12.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.23.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain<0.4.0,>=0.3.13->langchain_community) (0.3.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain_community) (24.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (3.10.12)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.12.14)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (1.26.20)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: anyio in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (4.7.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.0.7)\n",
      "Requirement already satisfied: sniffio in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/rajeev/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain_community) (1.2.2)\n",
      "Building wheels for collected packages: ibm-granite-community-utils\n",
      "  Building wheel for ibm-granite-community-utils (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ibm-granite-community-utils: filename=ibm_granite_community_utils-0.1.dev49-py3-none-any.whl size=8536 sha256=e10e9e7c4bf8e4fe0448b2b751d8640c3717efe2066b186f29232d06ebd97abc\n",
      "  Stored in directory: /private/var/folders/yq/mg65c_l16hv64plnb99z5dx40000gq/T/pip-ephem-wheel-cache-mtemf8hf/wheels/ee/16/b7/e10e3986779ca7e437370ddd3854cbbb6f9ddc27acf97a1405\n",
      "Successfully built ibm-granite-community-utils\n",
      "Installing collected packages: ibm-granite-community-utils\n",
      "  Attempting uninstall: ibm-granite-community-utils\n",
      "    Found existing installation: ibm-granite-community-utils 0.1.dev46\n",
      "    Uninstalling ibm-granite-community-utils-0.1.dev46:\n",
      "      Successfully uninstalled ibm-granite-community-utils-0.1.dev46\n",
      "Successfully installed ibm-granite-community-utils-0.1.dev49\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/utils langchain_community pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from ibm_granite_community.notebook_utils import get_env_var\n",
    "\n",
    "model_name: str = \"granite3.1-dense:8b\"\n",
    "\n",
    "model =  OllamaLLM(\n",
    "        model=model_name,\n",
    "        temperature=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Entity Extraction by defining entities in the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first approach is straightforward and involves explicitly defining the entities within the prompt itself. In this method, we specify the entities to be extracted along with their descriptions directly in the prompt. This includes:  \n",
    "\n",
    "<u>**Entity Definitions:**</u> Each entity, such as title, author, price, and rating, is clearly outlined with a concise description of what it represents.  \n",
    "\n",
    "<u>**Prompt Structure:**</u> The prompt is structured to guide the LLM in understanding exactly what information is needed. By providing detailed instructions, we aim to ensure that the model focuses on extracting only the relevant data.  \n",
    "\n",
    "<u>**Output Format:**</u> The output is required to be in JSON format, which enforces a consistent structure for the extracted data. If any entity is not found, the model is instructed to return \"Data not available,\" preventing ambiguity.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide some text with information for a book. In this case, we use generated commentary on 'The Hunger Games' by Suzanne Collins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_info = \"\"\"Notice of Representation\n",
    "\n",
    "Budget Mutual Insurance Company 9876 Infinity Ave Springfield, MI 65541\n",
    "\n",
    "Georgia Collan Parker LLP 9816 51st Ave SW Auburn, Washington(WA), 98092\n",
    "\n",
    "Our Client: Courtney Sosa Date of death: 6/12/2020\n",
    "\n",
    "To Whom It May Concern,\n",
    "\n",
    "I have been retained by Courtney Sosa to handle the estate of Lukas Juarez. My understanding is that they had a life insurance policy (#951033310) with your company. If this is correct, please send a letter to my office indicating you have received our letter of representation. Additionally, please do not contact our client going forward.\n",
    "\n",
    "We are requesting that you forward the full policy amount of $50,000. Please forward an acknowledgement of our demand and please forward the umbrella policy information if one is applicable. Please send my secretary any information regarding liens on his policy.\n",
    "\n",
    "Please contact my office if you have any questions.\n",
    "\n",
    "Sincerely,\n",
    "\n",
    "Angela Berry, Attorney\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the entities that need to be fetched are defined in the prompt itself along with the entity's description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_prompt = f\"\"\"\n",
    "<|start_of_role|>user<|end_of_role|>\n",
    "    -You are an AI Entity Extractor. You help extract entities from the given information about a book. Here is the book information:\n",
    "    {book_info}\n",
    "\n",
    "    - Extract the following entities:\n",
    "\n",
    "    1) `Insurance Company` : This is the name of the company.\n",
    "    2) `Insurance Company Address`: This is the address of the company.\n",
    "    3) `Law Firm`: Name of the Law Firm.\n",
    "    4) `Law Office Address`: This is the address of the law firm.\n",
    "\n",
    "    -Your output should strictly be in a json format, which only contains the key and value. The key here is the entity to be extracted and the value is the entity which you extracted.\n",
    "    -Do not generate random entities on your own. If it is not present or you are unable to find any specified entity, you strictly have to output it as `Data not available`.\n",
    "    -Only do what is asked to you. Do not give any explanations to your output and do not hallucinate.\n",
    "    <|end_of_text|>\n",
    "    <|start_of_role|>assistant<|end_of_role|>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the model to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"title\": \"The Hunger Games\",\n",
      "  \"author\": \"Suzanne Collins\",\n",
      "  \"price\": \"5 dollars and 9 cents\",\n",
      "  \"rating\": \"4.33/5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(entity_prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'The Hunger Games',\n",
       " 'author': 'Suzanne Collins',\n",
       " 'price': '5 dollars and 9 cents',\n",
       " 'rating': '4.33/5'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_info = json.loads(response)\n",
    "book_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Pydantic Class-Based Entity Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second approach takes advantage of object-oriented programming principles by defining entities within a class structure. This method involves several key steps:  \n",
    "\n",
    "<u>**Class Definition:**</u> We create a class that encapsulates all the relevant entities as members. Each member corresponds to an entity such as title, author, etc., and can include type annotations for better validation and clarity.  \n",
    "\n",
    "<u>**Pydantic Integration:**</u> Utilizing Pydantic, a data validation library, we convert this class into a Pydantic model. This model not only defines the structure of our data but also provides built-in validation features, ensuring that any extracted data adheres to specified formats and types.  \n",
    "\n",
    "<u>**Dynamic Prompting:**</u> The Pydantic model can then be integrated with the prompt sent to the LLM. This allows for a more dynamic interaction where the model can adapt based on the defined structure of entities. If new entities are added or existing ones modified, changes can be made at the class level without needing to rewrite the entire prompt.  \n",
    "\n",
    "<u>**Enhanced Validation:**</u> By leveraging Pydantic's capabilities, we can ensure that any data extracted by the LLM meets our predefined criteria, enhancing data integrity and reliability.  \n",
    "\n",
    "This class-based approach offers greater flexibility and scalability compared to the first method. It allows for easier modifications and expansions as new requirements arise, making it particularly suitable for larger projects or those requiring frequent updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use commentaries for two different books."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_info = f\"\"\"{book_info}\n",
    "\n",
    "Our next book is titled Magic of Lands. Even if some of you have read it before, I believe giving it another read would be worthwhile --\n",
    "it actually gets more captivating the second time around. The author, John Williams, who has several other books to his name,\n",
    "received a 3 out of 5 rating for this particular one. Considering the ratings we've seen for other books like Endurance, that's a fair score.\n",
    "This French drama is 330 pages long and was published on September 11, 2010. It's currently priced at $3.22.\n",
    "However, if you're interested, you can contact Mr. Shakespeare after the session -- he's offering it at a discounted price of $2.\n",
    "Don't miss the opportunity to grab such an intriguing read!\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all of the entities in a Python class along with the descripiton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Book(BaseModel):\n",
    "    \"This contains information about a book including its title, author, price, rating, and so on.\"\n",
    "    title: str = Field(description=\"The title of the book\")\n",
    "    price: str = Field(description=\"Total cost of this book\")\n",
    "    author: str = Field(description=\"The person who wrote this book\")\n",
    "    rating: str = Field(description=\"Total rating for this book\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooksInformation(BaseModel):\n",
    "    \"This contains information about multiple books.\"\n",
    "    books: List[Book] = Field(description = \"Information on multiple books. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'BooksInformation', 'description': 'This contains information about multiple books.', 'parameters': {'properties': {'books': {'description': 'Information on multiple books. ', 'items': {'description': 'This contains information about a book including its title, author, price, rating, and so on.', 'properties': {'title': {'description': 'The title of the book', 'type': 'string'}, 'price': {'description': 'Total cost of this book', 'type': 'string'}, 'author': {'description': 'The person who wrote this book', 'type': 'string'}, 'rating': {'description': 'Total rating for this book', 'type': 'string'}}, 'required': ['title', 'price', 'author', 'rating'], 'type': 'object'}, 'type': 'array'}}, 'required': ['books'], 'type': 'object'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yq/mg65c_l16hv64plnb99z5dx40000gq/T/ipykernel_3567/1048694277.py:1: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  book_function = convert_pydantic_to_openai_function(BooksInformation)\n"
     ]
    }
   ],
   "source": [
    "book_function = convert_pydantic_to_openai_function(BooksInformation)\n",
    "print(book_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same prompt as before, but here, the pydantic function is passed here instead of defining each entity in the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_prompt_with_pydantic = f\"\"\"\n",
    "<|start_of_role|>user<|end_of_role|>\n",
    "-You are an AI Entity Extractor. You help extract entities from the the given information about books: Here is the information about 2 books:\n",
    "\n",
    "{json.dumps(book_info)}\n",
    "\n",
    "-Analyze this information and extract the following entities as per this function definition:\n",
    "\n",
    "{json.dumps(book_function)}\n",
    "\n",
    "-Generate output as a json representation of a BooksInformation object. Include only the json.\n",
    "-Your output should strictly be in a json format, which only contains the key and value. The key here is the entity to be extracted and the value is the entity which you extracted.\n",
    "-Do not generate random entities on your own. If it is not present or you are unable to find any specified entity, you strictly have to output it as `Data not available`.\n",
    "-Only do what is asked to you. Do not give any explanations to your output and do not hallucinate.\n",
    "<|end_of_text|>\n",
    "<|start_of_role|>assistant<|end_of_role|>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoking the model to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"BooksInformation\": {\n",
      "    \"books\": [\n",
      "      {\n",
      "        \"title\": \"The Hunger Games\",\n",
      "        \"price\": \"5 dollars and 9 cents\",\n",
      "        \"author\": \"Suzanne Collins\",\n",
      "        \"rating\": \"4.33/5\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(entity_prompt_with_pydantic)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now instantiate the `Book` and `BooksInformation` classes with the extracted information. We'll need error handling in case we get an improperly-formatted response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BooksInformation': {'books': [{'title': 'The Hunger Games', 'price': '5 dollars and 9 cents', 'author': 'Suzanne Collins', 'rating': '4.33/5'}]}}\n",
      "The response does not contain the expected key 'books'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Parse the json response.\n",
    "    books_dict = json.loads(response)\n",
    "    print(books_dict)\n",
    "    try:\n",
    "        # Construct a list of Book objects from the response.\n",
    "        books_info = BooksInformation(books=[Book(**book) for book in books_dict['books']])\n",
    "        print(books_info)\n",
    "    except KeyError as e:\n",
    "        print(f\"The response does not contain the expected key '{e.args[0]}'\")\n",
    "except ValueError as e:\n",
    "    print(f\"Error while parsing response: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
