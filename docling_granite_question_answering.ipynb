{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail QA Agent using Granite 3.1 and Docling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Granite3.1 locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import the necessary libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 44d19d212d76... 100% ▕████████████████▏ 5.0 GB                         \n",
      "pulling f76a906816c4... 100% ▕████████████████▏ 1.4 KB                         \n",
      "pulling f7b956e70ca3... 100% ▕████████████████▏   69 B                         \n",
      "pulling 492069a62c25... 100% ▕████████████████▏  11 KB                         \n",
      "pulling f9cd69f4077d... 100% ▕████████████████▏  491 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n",
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull granite3.1-dense:8b\n",
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -q \"langchain>=0.1.0\" \"langchain-community>=0.0.13\" \"langchain-core>=0.1.17\" \\\n",
    "    \"langchain-ollama>=0.0.1\" \"pdfminer.six>=20221105\" \"markdown>=3.5.2\" \"docling>=2.0.0\" \\\n",
    "    \"beautifulsoup4>=4.12.0\" \"unstructured>=0.12.0\" \"chromadb>=0.4.22\" \"faiss-cpu>=1.7.4\" \\\n",
    "    \"requests>=2.32.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required imports\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# Docling imports\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions, TesseractCliOcrOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption, WordFormatOption, SimplePipeline\n",
    "\n",
    "# LangChain imports\n",
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Document format detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_format(file_path) -> InputFormat:\n",
    "    \"\"\"Determine the document format based on file extension\"\"\"\n",
    "    try:\n",
    "        file_path = str(file_path)\n",
    "        extension = os.path.splitext(file_path)[1].lower()\n",
    "\n",
    "        format_map = {\n",
    "            '.pdf': InputFormat.PDF,\n",
    "            '.docx': InputFormat.DOCX,\n",
    "            '.doc': InputFormat.DOCX,\n",
    "            '.pptx': InputFormat.PPTX,\n",
    "            '.html': InputFormat.HTML,\n",
    "            '.htm': InputFormat.HTML\n",
    "        }\n",
    "        return format_map.get(extension, None)\n",
    "    except:\n",
    "        return \"Error in get_document_format: {str(e)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Document conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_document_to_markdown(doc_path) -> str:\n",
    "    \"\"\"Convert document to markdown using simplified pipeline\"\"\"\n",
    "    try:\n",
    "        # Convert to absolute path string\n",
    "        input_path = os.path.abspath(str(doc_path))\n",
    "        print(f\"Converting document: {doc_path}\")\n",
    "\n",
    "        # Create temporary directory for processing\n",
    "        with tempfile.TemporaryDirectory() as temp_dir:\n",
    "            # Copy input file to temp directory\n",
    "            temp_input = os.path.join(temp_dir, os.path.basename(input_path))\n",
    "            shutil.copy2(input_path, temp_input)\n",
    "\n",
    "            # Configure pipeline options\n",
    "            pipeline_options = PdfPipelineOptions()\n",
    "            pipeline_options.do_ocr = False  # Disable OCR temporarily\n",
    "            pipeline_options.do_table_structure = True\n",
    "\n",
    "            # Create converter with minimal options\n",
    "            converter = DocumentConverter(\n",
    "                allowed_formats=[\n",
    "                    InputFormat.PDF,\n",
    "                    InputFormat.DOCX,\n",
    "                    InputFormat.HTML,\n",
    "                    InputFormat.PPTX,\n",
    "                ],\n",
    "                format_options={\n",
    "                    InputFormat.PDF: PdfFormatOption(\n",
    "                        pipeline_options=pipeline_options,\n",
    "                    ),\n",
    "                    InputFormat.DOCX: WordFormatOption(\n",
    "                        pipeline_cls=SimplePipeline\n",
    "                    )\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Convert document\n",
    "            print(\"Starting conversion...\")\n",
    "            conv_result = converter.convert(temp_input)\n",
    "\n",
    "            if not conv_result or not conv_result.document:\n",
    "                raise ValueError(f\"Failed to convert document: {doc_path}\")\n",
    "\n",
    "            # Export to markdown\n",
    "            print(\"Exporting to markdown...\")\n",
    "            md = conv_result.document.export_to_markdown()\n",
    "\n",
    "            # Create output path\n",
    "            output_dir = os.path.dirname(input_path)\n",
    "            base_name = os.path.splitext(os.path.basename(input_path))[0]\n",
    "            md_path = os.path.join(output_dir, f\"{base_name}_converted.md\")\n",
    "\n",
    "            # Write markdown file\n",
    "            print(f\"Writing markdown to: {base_name}_converted.md\")\n",
    "            with open(md_path, \"w\", encoding=\"utf-8\") as fp:\n",
    "                fp.write(md)\n",
    "\n",
    "            return md_path\n",
    "    except:\n",
    "        return f\"Error converting document: {doc_path}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. QA chain setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_qa_chain(markdown_path: Path, embeddings_model_name:str = \"nomic-embed-text:latest\", model_name: str = \"granite3.1-dense:8b\"):\n",
    "    \"\"\"Set up the QA chain for document processing\"\"\"\n",
    "    # Load and split the document\n",
    "    loader = UnstructuredMarkdownLoader(str(markdown_path)) \n",
    "    documents = loader.load()\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=50,\n",
    "        length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    # texts= documents\n",
    "    \n",
    "    # Create embeddings and vector store\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=embeddings_model_name\n",
    "        )\n",
    "    vectorstore = FAISS.from_documents(texts, embeddings)\n",
    "    \n",
    "    # Initialize LLM\n",
    "    llm = OllamaLLM(\n",
    "        model=model_name,\n",
    "        temperature=0\n",
    "    )\n",
    "    \n",
    "    # Set up conversation memory\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\",\n",
    "        output_key=\"answer\",\n",
    "        return_messages=True\n",
    "    )\n",
    "    \n",
    "    # Create the chain\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=vectorstore.as_retriever(\n",
    "            search_kwargs={\"k\": 10}\n",
    "            ),\n",
    "        memory=memory,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    \n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Set up question-answering interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(qa_chain, question: str):\n",
    "    \"\"\"Ask a question and display the answer\"\"\"\n",
    "    result = qa_chain.invoke({\"question\": question})\n",
    "    display(Markdown(f\"**Question:** {question}\\n\\n**Answer:** {result['answer']}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Ask Questions to the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting document: l0.pdf\n",
      "Starting conversion...\n",
      "Exporting to markdown...\n",
      "Writing markdown to: l0_converted.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What is the main topic of this document?\n",
       "\n",
       "**Answer:** The main topic of this document is a legal request related to an insurance policy. Angela Berry, an attorney, has been retained by Courtney Sosa to handle the estate of Lukas Juarez. The letter informs Budget Mutual Insurance Company that they represent Courtney Sosa and are requesting information about a life insurance policy (#951033310) held by Lukas Juarez with their company. The attorney also asks for confirmation of receipt of the representation letter and instructs the insurance company not to contact their client directly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** What are the key points discussed?\n",
       "\n",
       "**Answer:** The main details outlined in this legal request are as follows:\n",
       "\n",
       "1. The sender, Angela Berry, is an attorney representing Courtney Sosa in the estate of Lukas Juarez.\n",
       "2. The deceased individual, Lukas Juarez, had a life insurance policy with Budget Mutual Insurance Company, identified by the number #951033310.\n",
       "3. The attorney is requesting that the full policy amount of $50,000 be forwarded to her office.\n",
       "4. She also asks for an acknowledgement of their demand and requests umbrella policy information if applicable.\n",
       "5. The attorney's secretary should receive any information regarding liens on the policy.\n",
       "6. The sender has instructed that the insurance company should not contact their client (Courtney Sosa) going forward.\n",
       "7. The letter serves as a Notice of Representation, indicating that the law firm is now handling the estate's matters related to this insurance policy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Question:** Can you summarize the conclusions?\n",
       "\n",
       "**Answer:** Angela Berry, an attorney representing Courtney Sosa, has written a letter to Budget Mutual Insurance Company regarding Lukas Juarez's life insurance policy (#951033310). The key points of her request are:\n",
       "\n",
       "1. Acknowledgment of Representation: She requests that the insurance company acknowledge receipt of their letter of representation, indicating they have been informed about her role as the legal representative for Courtney Sosa.\n",
       "\n",
       "2. Policy Amount and Forwarding: Angela Berry asks for the full policy amount of $50,000 to be forwarded to her office. This suggests that Lukas Juarez's life insurance policy has a death benefit of $50,000.\n",
       "\n",
       "3. Acknowledgement of Demand: She requests an acknowledgement from the insurance company regarding their demand for the full policy amount.\n",
       "\n",
       "4. Umbrella Policy Information: If applicable, she asks for information about any umbrella policies that might be linked to Lukas Juarez's life insurance policy.\n",
       "\n",
       "5. Liens Information: She requests any information related to liens on Lukas Juarez's policy. This could indicate potential debts or claims against the policy before distribution to the beneficiary, Courtney Sosa.\n",
       "\n",
       "6. Communication Instructions: Angela Berry instructs the insurance company not to contact their client (Courtney Sosa) directly regarding this matter, implying that all communication should go through her office.\n",
       "\n",
       "In summary, Angela Berry is requesting the full death benefit from Lukas Juarez's life insurance policy, along with related information and documentation, while instructing the insurance company to communicate only with her office concerning this matter."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process a document\n",
    "doc_path = Path(\"l0.pdf\")  # Replace with your document path\n",
    "\n",
    "# Check format and process\n",
    "doc_format = get_document_format(doc_path)\n",
    "if doc_format:\n",
    "    md_path = convert_document_to_markdown(doc_path)\n",
    "    qa_chain = setup_qa_chain(md_path)\n",
    "    \n",
    "    # Example questions\n",
    "    questions = [\n",
    "        \"What is the main topic of this document?\",\n",
    "        \"What are the key points discussed?\",\n",
    "        \"Can you summarize the conclusions?\",\n",
    "    ]\n",
    "    \n",
    "    for question in questions:\n",
    "        ask_question(qa_chain, question)\n",
    "else:\n",
    "    print(f\"Unsupported document format: {doc_path.suffix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "\n",
    "Using Docling and Granite 3.1, we have built a question answering system for Retail Documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
